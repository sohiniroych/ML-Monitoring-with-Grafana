{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we will apply data generator to monitor test outcome on Grafana dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras to load the data\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data set is Boston Housing Prices classification data set https://www.kaggle.com/vikrishnan/boston-house-prices\n",
    "## Step 1: Pre-process the data (normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features per sample= 13\n"
     ]
    }
   ],
   "source": [
    "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()\n",
    "\n",
    "# get per-feature statistics (mean, standard deviation) from the training set to normalize by\n",
    "train_mean = np.mean(train_features, axis=0)\n",
    "train_std = np.std(train_features, axis=0)\n",
    "train_features = (train_features - train_mean) / train_std\n",
    "print(\"Number of features per sample=\", np.shape(train_features)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for test features\n",
    "test_mean = np.mean(test_features, axis=0)\n",
    "test_std = np.std(test_features, axis=0)\n",
    "test_features = (test_features - test_mean) / test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define a simple Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    model = keras.Sequential([\n",
    "        Dense(100, activation=tf.nn.relu, input_shape=[len(train_features[0])]),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(), \n",
    "                  loss='mse',\n",
    "                  metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, lets train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 585.5373 - mae: 22.2635 - mse: 585.5373 - val_loss: 480.0441 - val_mae: 20.9236 - val_mse: 480.0441\n",
      "Epoch 2/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 557.7109 - mae: 21.6735 - mse: 557.7109 - val_loss: 455.4070 - val_mae: 20.3228 - val_mse: 455.4070\n",
      "Epoch 3/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 530.4736 - mae: 21.0639 - mse: 530.4736 - val_loss: 430.2127 - val_mae: 19.6977 - val_mse: 430.2127\n",
      "Epoch 4/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 502.0010 - mae: 20.4162 - mse: 502.0010 - val_loss: 403.8715 - val_mae: 19.0149 - val_mse: 403.8715\n",
      "Epoch 5/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 472.7788 - mae: 19.7203 - mse: 472.7788 - val_loss: 375.4177 - val_mae: 18.2614 - val_mse: 375.4177\n",
      "Epoch 6/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 439.5832 - mae: 18.9327 - mse: 439.5832 - val_loss: 346.1937 - val_mae: 17.4488 - val_mse: 346.1937\n",
      "Epoch 7/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 407.2911 - mae: 18.1121 - mse: 407.2911 - val_loss: 314.7846 - val_mae: 16.5953 - val_mse: 314.7846\n",
      "Epoch 8/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 372.1576 - mae: 17.1847 - mse: 372.1576 - val_loss: 283.7415 - val_mae: 15.6969 - val_mse: 283.7415\n",
      "Epoch 9/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 337.1841 - mae: 16.2359 - mse: 337.1841 - val_loss: 253.3473 - val_mae: 14.7489 - val_mse: 253.3473\n",
      "Epoch 10/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 304.2076 - mae: 15.2676 - mse: 304.2076 - val_loss: 222.8236 - val_mae: 13.7175 - val_mse: 222.8236\n",
      "Epoch 11/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 269.9142 - mae: 14.2300 - mse: 269.9142 - val_loss: 194.0440 - val_mae: 12.6531 - val_mse: 194.0440\n",
      "Epoch 12/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 237.9029 - mae: 13.1750 - mse: 237.9029 - val_loss: 167.5503 - val_mae: 11.5968 - val_mse: 167.5503\n",
      "Epoch 13/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 208.5724 - mae: 12.1227 - mse: 208.5724 - val_loss: 143.6604 - val_mae: 10.5356 - val_mse: 143.6604\n",
      "Epoch 14/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 181.6628 - mae: 11.1278 - mse: 181.6628 - val_loss: 122.7017 - val_mae: 9.5094 - val_mse: 122.7017\n",
      "Epoch 15/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 158.0390 - mae: 10.2065 - mse: 158.0390 - val_loss: 105.3162 - val_mae: 8.6540 - val_mse: 105.3162\n",
      "Epoch 16/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 138.3024 - mae: 9.3964 - mse: 138.3024 - val_loss: 90.4794 - val_mae: 8.0066 - val_mse: 90.4794\n",
      "Epoch 17/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 120.5511 - mae: 8.6977 - mse: 120.5511 - val_loss: 78.7417 - val_mae: 7.5013 - val_mse: 78.7417\n",
      "Epoch 18/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 106.7478 - mae: 8.0914 - mse: 106.7478 - val_loss: 69.0199 - val_mae: 7.0394 - val_mse: 69.0199\n",
      "Epoch 19/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 94.1554 - mae: 7.5475 - mse: 94.1554 - val_loss: 61.1114 - val_mae: 6.6485 - val_mse: 61.1114\n",
      "Epoch 20/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 84.1525 - mae: 7.0576 - mse: 84.1525 - val_loss: 54.6782 - val_mae: 6.3019 - val_mse: 54.6782\n",
      "Epoch 21/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 75.2611 - mae: 6.6311 - mse: 75.2611 - val_loss: 49.4799 - val_mae: 5.9596 - val_mse: 49.4799\n",
      "Epoch 22/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 67.7311 - mae: 6.2643 - mse: 67.7311 - val_loss: 44.9199 - val_mae: 5.6103 - val_mse: 44.9199\n",
      "Epoch 23/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 61.0318 - mae: 5.9196 - mse: 61.0318 - val_loss: 41.1684 - val_mae: 5.3519 - val_mse: 41.1684\n",
      "Epoch 24/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 55.3356 - mae: 5.6072 - mse: 55.3356 - val_loss: 37.8121 - val_mae: 5.1256 - val_mse: 37.8121\n",
      "Epoch 25/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 50.1953 - mae: 5.3012 - mse: 50.1953 - val_loss: 35.1146 - val_mae: 4.9280 - val_mse: 35.1146\n",
      "Epoch 26/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 46.0827 - mae: 5.0524 - mse: 46.0827 - val_loss: 32.8552 - val_mae: 4.7535 - val_mse: 32.8552\n",
      "Epoch 27/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 42.5698 - mae: 4.8041 - mse: 42.5698 - val_loss: 30.8903 - val_mae: 4.5858 - val_mse: 30.8903\n",
      "Epoch 28/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 39.7110 - mae: 4.6078 - mse: 39.7110 - val_loss: 29.4781 - val_mae: 4.4723 - val_mse: 29.4781\n",
      "Epoch 29/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 37.1232 - mae: 4.4197 - mse: 37.1232 - val_loss: 28.3255 - val_mae: 4.3640 - val_mse: 28.3255\n",
      "Epoch 30/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 35.0746 - mae: 4.2628 - mse: 35.0746 - val_loss: 27.3449 - val_mae: 4.2560 - val_mse: 27.3449\n",
      "Epoch 31/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5217 - mae: 4.1281 - mse: 33.5217 - val_loss: 26.6099 - val_mae: 4.1800 - val_mse: 26.6099\n",
      "Epoch 32/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.1507 - mae: 4.0155 - mse: 32.1507 - val_loss: 26.0890 - val_mae: 4.1146 - val_mse: 26.0890\n",
      "Epoch 33/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.9693 - mae: 3.9307 - mse: 30.9693 - val_loss: 25.6387 - val_mae: 4.0510 - val_mse: 25.6387\n",
      "Epoch 34/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.8980 - mae: 3.8627 - mse: 29.8980 - val_loss: 25.1257 - val_mae: 3.9952 - val_mse: 25.1257\n",
      "Epoch 35/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 29.0558 - mae: 3.8176 - mse: 29.0558 - val_loss: 24.9580 - val_mae: 3.9709 - val_mse: 24.9580\n",
      "Epoch 36/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 28.2852 - mae: 3.7637 - mse: 28.2852 - val_loss: 24.7080 - val_mae: 3.9561 - val_mse: 24.7080\n",
      "Epoch 37/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 27.7275 - mae: 3.7324 - mse: 27.7275 - val_loss: 24.5977 - val_mae: 3.9504 - val_mse: 24.5977\n",
      "Epoch 38/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.1238 - mae: 3.6948 - mse: 27.1238 - val_loss: 24.4017 - val_mae: 3.9246 - val_mse: 24.4017\n",
      "Epoch 39/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.6057 - mae: 3.6533 - mse: 26.6057 - val_loss: 24.4569 - val_mae: 3.9222 - val_mse: 24.4569\n",
      "Epoch 40/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 26.1413 - mae: 3.6234 - mse: 26.1413 - val_loss: 24.4366 - val_mae: 3.9155 - val_mse: 24.4366\n",
      "Epoch 41/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 25.7491 - mae: 3.6041 - mse: 25.7491 - val_loss: 24.1911 - val_mae: 3.8842 - val_mse: 24.1911\n",
      "Epoch 42/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 25.3468 - mae: 3.5738 - mse: 25.3468 - val_loss: 23.9128 - val_mae: 3.8481 - val_mse: 23.9128\n",
      "Epoch 43/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 24.9359 - mae: 3.5389 - mse: 24.9359 - val_loss: 23.4210 - val_mae: 3.7901 - val_mse: 23.4210\n",
      "Epoch 44/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 24.5600 - mae: 3.5179 - mse: 24.5600 - val_loss: 23.2792 - val_mae: 3.7702 - val_mse: 23.2792\n",
      "Epoch 45/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 24.1534 - mae: 3.4881 - mse: 24.1534 - val_loss: 23.1660 - val_mae: 3.7509 - val_mse: 23.1660\n",
      "Epoch 46/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23.8088 - mae: 3.4630 - mse: 23.8088 - val_loss: 22.9677 - val_mae: 3.7253 - val_mse: 22.9677\n",
      "Epoch 47/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23.4673 - mae: 3.4396 - mse: 23.4673 - val_loss: 22.7703 - val_mae: 3.6915 - val_mse: 22.7703\n",
      "Epoch 48/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23.0970 - mae: 3.4169 - mse: 23.0970 - val_loss: 22.3943 - val_mae: 3.6380 - val_mse: 22.3943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 22.7479 - mae: 3.3953 - mse: 22.7479 - val_loss: 22.1266 - val_mae: 3.6077 - val_mse: 22.1266\n",
      "Epoch 50/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 22.4473 - mae: 3.3688 - mse: 22.4473 - val_loss: 21.8677 - val_mae: 3.5703 - val_mse: 21.8677\n",
      "Epoch 51/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 22.1258 - mae: 3.3450 - mse: 22.1258 - val_loss: 21.6342 - val_mae: 3.5415 - val_mse: 21.6342\n",
      "Epoch 52/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 21.8239 - mae: 3.3207 - mse: 21.8239 - val_loss: 21.3131 - val_mae: 3.5056 - val_mse: 21.3131\n",
      "Epoch 53/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 21.5297 - mae: 3.2951 - mse: 21.5297 - val_loss: 21.0945 - val_mae: 3.4762 - val_mse: 21.0945\n",
      "Epoch 54/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 21.2458 - mae: 3.2800 - mse: 21.2458 - val_loss: 20.9931 - val_mae: 3.4733 - val_mse: 20.9931\n",
      "Epoch 55/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 20.9116 - mae: 3.2595 - mse: 20.9116 - val_loss: 20.8616 - val_mae: 3.4404 - val_mse: 20.8616\n",
      "Epoch 56/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 20.6208 - mae: 3.2278 - mse: 20.6208 - val_loss: 20.6638 - val_mae: 3.4121 - val_mse: 20.6638\n",
      "Epoch 57/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 20.3306 - mae: 3.2048 - mse: 20.3306 - val_loss: 20.3355 - val_mae: 3.3824 - val_mse: 20.3355\n",
      "Epoch 58/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 20.0619 - mae: 3.1908 - mse: 20.0619 - val_loss: 19.9152 - val_mae: 3.3462 - val_mse: 19.9152\n",
      "Epoch 59/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.9213 - mae: 3.1850 - mse: 19.9213 - val_loss: 19.8022 - val_mae: 3.3343 - val_mse: 19.8022\n",
      "Epoch 60/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.5163 - mae: 3.1542 - mse: 19.5163 - val_loss: 19.5005 - val_mae: 3.3062 - val_mse: 19.5005\n",
      "Epoch 61/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.3084 - mae: 3.1253 - mse: 19.3084 - val_loss: 19.2350 - val_mae: 3.2772 - val_mse: 19.2350\n",
      "Epoch 62/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.0465 - mae: 3.1061 - mse: 19.0465 - val_loss: 19.1097 - val_mae: 3.2605 - val_mse: 19.1097\n",
      "Epoch 63/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.7741 - mae: 3.0872 - mse: 18.7741 - val_loss: 18.8259 - val_mae: 3.2379 - val_mse: 18.8259\n",
      "Epoch 64/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.5331 - mae: 3.0708 - mse: 18.5331 - val_loss: 18.6290 - val_mae: 3.2212 - val_mse: 18.6290\n",
      "Epoch 65/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.2904 - mae: 3.0484 - mse: 18.2904 - val_loss: 18.4634 - val_mae: 3.2063 - val_mse: 18.4634\n",
      "Epoch 66/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.0679 - mae: 3.0314 - mse: 18.0679 - val_loss: 18.2208 - val_mae: 3.1845 - val_mse: 18.2208\n",
      "Epoch 67/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.9240 - mae: 3.0084 - mse: 17.9240 - val_loss: 17.9113 - val_mae: 3.1785 - val_mse: 17.9113\n",
      "Epoch 68/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.6220 - mae: 2.9777 - mse: 17.6220 - val_loss: 17.6128 - val_mae: 3.1327 - val_mse: 17.6128\n",
      "Epoch 69/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.4384 - mae: 2.9652 - mse: 17.4384 - val_loss: 17.2934 - val_mae: 3.1053 - val_mse: 17.2934\n",
      "Epoch 70/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 17.1960 - mae: 2.9436 - mse: 17.1960 - val_loss: 16.9760 - val_mae: 3.0796 - val_mse: 16.9760\n",
      "Epoch 71/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 16.9967 - mae: 2.9274 - mse: 16.9967 - val_loss: 16.7190 - val_mae: 3.0518 - val_mse: 16.7190\n",
      "Epoch 72/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.8037 - mae: 2.9128 - mse: 16.8037 - val_loss: 16.4970 - val_mae: 3.0324 - val_mse: 16.4970\n",
      "Epoch 73/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.6003 - mae: 2.8882 - mse: 16.6003 - val_loss: 16.2015 - val_mae: 3.0195 - val_mse: 16.2015\n",
      "Epoch 74/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.4438 - mae: 2.8621 - mse: 16.4438 - val_loss: 16.0148 - val_mae: 3.0145 - val_mse: 16.0148\n",
      "Epoch 75/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.2218 - mae: 2.8437 - mse: 16.2218 - val_loss: 15.9210 - val_mae: 3.0011 - val_mse: 15.9210\n",
      "Epoch 76/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.0386 - mae: 2.8349 - mse: 16.0386 - val_loss: 15.8326 - val_mae: 2.9892 - val_mse: 15.8326\n",
      "Epoch 77/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.8250 - mae: 2.8167 - mse: 15.8250 - val_loss: 15.4657 - val_mae: 2.9585 - val_mse: 15.4657\n",
      "Epoch 78/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.6472 - mae: 2.7969 - mse: 15.6472 - val_loss: 15.2932 - val_mae: 2.9475 - val_mse: 15.2932\n",
      "Epoch 79/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.4961 - mae: 2.7774 - mse: 15.4961 - val_loss: 15.2261 - val_mae: 2.9510 - val_mse: 15.2261\n",
      "Epoch 80/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.3209 - mae: 2.7593 - mse: 15.3209 - val_loss: 15.1073 - val_mae: 2.9413 - val_mse: 15.1073\n",
      "Epoch 81/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.1524 - mae: 2.7375 - mse: 15.1524 - val_loss: 14.6990 - val_mae: 2.9264 - val_mse: 14.6990\n",
      "Epoch 82/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.8971 - mae: 2.7228 - mse: 14.8971 - val_loss: 14.4602 - val_mae: 2.8631 - val_mse: 14.4602\n",
      "Epoch 83/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.7655 - mae: 2.7197 - mse: 14.7655 - val_loss: 14.3542 - val_mae: 2.8552 - val_mse: 14.3542\n",
      "Epoch 84/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.6904 - mae: 2.7070 - mse: 14.6904 - val_loss: 14.4329 - val_mae: 2.9035 - val_mse: 14.4329\n",
      "Epoch 85/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.3970 - mae: 2.6947 - mse: 14.3970 - val_loss: 14.4017 - val_mae: 2.8577 - val_mse: 14.4017\n",
      "Epoch 86/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.3110 - mae: 2.6938 - mse: 14.3110 - val_loss: 14.1299 - val_mae: 2.8397 - val_mse: 14.1299\n",
      "Epoch 87/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.1559 - mae: 2.6730 - mse: 14.1559 - val_loss: 14.0271 - val_mae: 2.8491 - val_mse: 14.0271\n",
      "Epoch 88/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.9522 - mae: 2.6485 - mse: 13.9522 - val_loss: 13.8588 - val_mae: 2.8409 - val_mse: 13.8588\n",
      "Epoch 89/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.7704 - mae: 2.6241 - mse: 13.7704 - val_loss: 13.6224 - val_mae: 2.8318 - val_mse: 13.6224\n",
      "Epoch 90/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.6347 - mae: 2.6059 - mse: 13.6347 - val_loss: 13.3770 - val_mae: 2.8229 - val_mse: 13.3770\n",
      "Epoch 91/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.4803 - mae: 2.5889 - mse: 13.4803 - val_loss: 13.2132 - val_mae: 2.8236 - val_mse: 13.2132\n",
      "Epoch 92/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.3296 - mae: 2.5665 - mse: 13.3296 - val_loss: 12.9904 - val_mae: 2.8154 - val_mse: 12.9904\n",
      "Epoch 93/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.1859 - mae: 2.5498 - mse: 13.1859 - val_loss: 12.7676 - val_mae: 2.8059 - val_mse: 12.7676\n",
      "Epoch 94/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.0708 - mae: 2.5351 - mse: 13.0708 - val_loss: 12.4367 - val_mae: 2.7740 - val_mse: 12.4367\n",
      "Epoch 95/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.9278 - mae: 2.5180 - mse: 12.9278 - val_loss: 12.1948 - val_mae: 2.7497 - val_mse: 12.1948\n",
      "Epoch 96/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.8071 - mae: 2.5006 - mse: 12.8071 - val_loss: 11.9957 - val_mae: 2.7472 - val_mse: 11.9957\n",
      "Epoch 97/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.6504 - mae: 2.4825 - mse: 12.6504 - val_loss: 11.7879 - val_mae: 2.7191 - val_mse: 11.7879\n",
      "Epoch 98/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.5717 - mae: 2.4854 - mse: 12.5717 - val_loss: 11.8257 - val_mae: 2.6895 - val_mse: 11.8257\n",
      "Epoch 99/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.3938 - mae: 2.4757 - mse: 12.3938 - val_loss: 11.5767 - val_mae: 2.6729 - val_mse: 11.5767\n",
      "Epoch 100/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.2380 - mae: 2.4522 - mse: 12.2380 - val_loss: 11.4806 - val_mae: 2.7027 - val_mse: 11.4806\n",
      "Epoch 101/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.1274 - mae: 2.4318 - mse: 12.1274 - val_loss: 11.2675 - val_mae: 2.6915 - val_mse: 11.2675\n",
      "Epoch 102/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.0109 - mae: 2.4199 - mse: 12.0109 - val_loss: 11.0141 - val_mae: 2.6565 - val_mse: 11.0141\n",
      "Epoch 103/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.8940 - mae: 2.4110 - mse: 11.8940 - val_loss: 10.9327 - val_mae: 2.6535 - val_mse: 10.9327\n",
      "Epoch 104/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.8175 - mae: 2.3932 - mse: 11.8175 - val_loss: 10.9611 - val_mae: 2.6737 - val_mse: 10.9611\n",
      "Epoch 105/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.7102 - mae: 2.3864 - mse: 11.7102 - val_loss: 10.5014 - val_mae: 2.6059 - val_mse: 10.5014\n",
      "Epoch 106/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.5586 - mae: 2.3702 - mse: 11.5586 - val_loss: 10.3778 - val_mae: 2.5994 - val_mse: 10.3778\n",
      "Epoch 107/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.4816 - mae: 2.3683 - mse: 11.4816 - val_loss: 10.4126 - val_mae: 2.5862 - val_mse: 10.4126\n",
      "Epoch 108/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.3545 - mae: 2.3625 - mse: 11.3545 - val_loss: 10.2817 - val_mae: 2.5635 - val_mse: 10.2817\n",
      "Epoch 109/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.2476 - mae: 2.3495 - mse: 11.2476 - val_loss: 10.2571 - val_mae: 2.5874 - val_mse: 10.2571\n",
      "Epoch 110/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.1454 - mae: 2.3354 - mse: 11.1454 - val_loss: 10.0108 - val_mae: 2.5587 - val_mse: 10.0108\n",
      "Epoch 111/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.0567 - mae: 2.3253 - mse: 11.0567 - val_loss: 10.0226 - val_mae: 2.5775 - val_mse: 10.0226\n",
      "Epoch 112/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.9851 - mae: 2.3167 - mse: 10.9851 - val_loss: 10.0211 - val_mae: 2.5845 - val_mse: 10.0211\n",
      "Epoch 113/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.8927 - mae: 2.3051 - mse: 10.8927 - val_loss: 9.6494 - val_mae: 2.5348 - val_mse: 9.6494\n",
      "Epoch 114/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.8167 - mae: 2.2951 - mse: 10.8167 - val_loss: 9.4652 - val_mae: 2.5167 - val_mse: 9.4652\n",
      "Epoch 115/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.6988 - mae: 2.2830 - mse: 10.6988 - val_loss: 9.3946 - val_mae: 2.5035 - val_mse: 9.3946\n",
      "Epoch 116/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.6207 - mae: 2.2750 - mse: 10.6207 - val_loss: 9.2998 - val_mae: 2.4938 - val_mse: 9.2998\n",
      "Epoch 117/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.5523 - mae: 2.2700 - mse: 10.5523 - val_loss: 9.1998 - val_mae: 2.4770 - val_mse: 9.1998\n",
      "Epoch 118/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.4784 - mae: 2.2614 - mse: 10.4784 - val_loss: 9.1707 - val_mae: 2.4808 - val_mse: 9.1707\n",
      "Epoch 119/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.4007 - mae: 2.2514 - mse: 10.4007 - val_loss: 9.0247 - val_mae: 2.4723 - val_mse: 9.0247\n",
      "Epoch 120/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.3503 - mae: 2.2436 - mse: 10.3503 - val_loss: 8.9919 - val_mae: 2.4844 - val_mse: 8.9919\n",
      "Epoch 121/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.2868 - mae: 2.2404 - mse: 10.2868 - val_loss: 8.7671 - val_mae: 2.4300 - val_mse: 8.7671\n",
      "Epoch 122/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.1957 - mae: 2.2318 - mse: 10.1957 - val_loss: 8.8268 - val_mae: 2.4505 - val_mse: 8.8268\n",
      "Epoch 123/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.1270 - mae: 2.2245 - mse: 10.1270 - val_loss: 8.6947 - val_mae: 2.4382 - val_mse: 8.6947\n",
      "Epoch 124/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.0598 - mae: 2.2163 - mse: 10.0598 - val_loss: 8.6060 - val_mae: 2.4327 - val_mse: 8.6060\n",
      "Epoch 125/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.9964 - mae: 2.2115 - mse: 9.9964 - val_loss: 8.6166 - val_mae: 2.4320 - val_mse: 8.6166\n",
      "Epoch 126/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.9520 - mae: 2.2092 - mse: 9.9520 - val_loss: 8.5550 - val_mae: 2.4122 - val_mse: 8.5550\n",
      "Epoch 127/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.9117 - mae: 2.2058 - mse: 9.9117 - val_loss: 8.3419 - val_mae: 2.4071 - val_mse: 8.3419\n",
      "Epoch 128/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.8197 - mae: 2.1964 - mse: 9.8197 - val_loss: 8.1861 - val_mae: 2.3733 - val_mse: 8.1861\n",
      "Epoch 129/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.8183 - mae: 2.1893 - mse: 9.8183 - val_loss: 8.2282 - val_mae: 2.4008 - val_mse: 8.2282\n",
      "Epoch 130/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.7231 - mae: 2.1846 - mse: 9.7231 - val_loss: 8.1683 - val_mae: 2.3815 - val_mse: 8.1683\n",
      "Epoch 131/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.6548 - mae: 2.1784 - mse: 9.6548 - val_loss: 8.1747 - val_mae: 2.3884 - val_mse: 8.1747\n",
      "Epoch 132/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.6241 - mae: 2.1727 - mse: 9.6241 - val_loss: 8.2323 - val_mae: 2.4029 - val_mse: 8.2323\n",
      "Epoch 133/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.5732 - mae: 2.1720 - mse: 9.5732 - val_loss: 8.0894 - val_mae: 2.3536 - val_mse: 8.0894\n",
      "Epoch 134/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.5332 - mae: 2.1656 - mse: 9.5332 - val_loss: 8.0656 - val_mae: 2.3627 - val_mse: 8.0656\n",
      "Epoch 135/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.5122 - mae: 2.1628 - mse: 9.5122 - val_loss: 8.0968 - val_mae: 2.3956 - val_mse: 8.0968\n",
      "Epoch 136/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.4209 - mae: 2.1522 - mse: 9.4209 - val_loss: 7.9712 - val_mae: 2.3718 - val_mse: 7.9712\n",
      "Epoch 137/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.3945 - mae: 2.1553 - mse: 9.3945 - val_loss: 7.6613 - val_mae: 2.2705 - val_mse: 7.6613\n",
      "Epoch 138/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.3621 - mae: 2.1454 - mse: 9.3621 - val_loss: 7.7406 - val_mae: 2.3275 - val_mse: 7.7406\n",
      "Epoch 139/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.2960 - mae: 2.1395 - mse: 9.2960 - val_loss: 7.7796 - val_mae: 2.3482 - val_mse: 7.7796\n",
      "Epoch 140/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.2874 - mae: 2.1361 - mse: 9.2874 - val_loss: 7.6886 - val_mae: 2.3073 - val_mse: 7.6886\n",
      "Epoch 141/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.2143 - mae: 2.1327 - mse: 9.2143 - val_loss: 7.8090 - val_mae: 2.3495 - val_mse: 7.8090\n",
      "Epoch 142/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.1877 - mae: 2.1247 - mse: 9.1877 - val_loss: 7.6006 - val_mae: 2.3278 - val_mse: 7.6006\n",
      "Epoch 143/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.1262 - mae: 2.1161 - mse: 9.1262 - val_loss: 7.5415 - val_mae: 2.3185 - val_mse: 7.5415\n",
      "Epoch 144/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.0813 - mae: 2.1136 - mse: 9.0813 - val_loss: 7.4039 - val_mae: 2.2743 - val_mse: 7.4039\n",
      "Epoch 145/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.0804 - mae: 2.1126 - mse: 9.0804 - val_loss: 7.3527 - val_mae: 2.2877 - val_mse: 7.3527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.0470 - mae: 2.1084 - mse: 9.0470 - val_loss: 7.3825 - val_mae: 2.2894 - val_mse: 7.3825\n",
      "Epoch 147/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.0653 - mae: 2.0975 - mse: 9.0653 - val_loss: 7.4627 - val_mae: 2.3410 - val_mse: 7.4627\n",
      "Epoch 148/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.9542 - mae: 2.0950 - mse: 8.9542 - val_loss: 7.2587 - val_mae: 2.2431 - val_mse: 7.2587\n",
      "Epoch 149/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.9503 - mae: 2.1037 - mse: 8.9503 - val_loss: 7.3271 - val_mae: 2.2620 - val_mse: 7.3271\n",
      "Epoch 150/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.9093 - mae: 2.0943 - mse: 8.9093 - val_loss: 7.3987 - val_mae: 2.3023 - val_mse: 7.3987\n",
      "Epoch 151/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.9557 - mae: 2.1038 - mse: 8.9557 - val_loss: 7.1811 - val_mae: 2.2432 - val_mse: 7.1811\n",
      "Epoch 152/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.8181 - mae: 2.0799 - mse: 8.8181 - val_loss: 7.2993 - val_mae: 2.2977 - val_mse: 7.2993\n",
      "Epoch 153/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.8269 - mae: 2.0770 - mse: 8.8269 - val_loss: 7.2766 - val_mae: 2.3020 - val_mse: 7.2766\n",
      "Epoch 154/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.7403 - mae: 2.0712 - mse: 8.7403 - val_loss: 6.9546 - val_mae: 2.1992 - val_mse: 6.9546\n",
      "Epoch 155/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.7585 - mae: 2.0768 - mse: 8.7585 - val_loss: 6.9769 - val_mae: 2.2157 - val_mse: 6.9769\n",
      "Epoch 156/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.7003 - mae: 2.0717 - mse: 8.7003 - val_loss: 7.1281 - val_mae: 2.2714 - val_mse: 7.1281\n",
      "Epoch 157/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.6730 - mae: 2.0583 - mse: 8.6730 - val_loss: 7.1074 - val_mae: 2.2794 - val_mse: 7.1074\n",
      "Epoch 158/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.6616 - mae: 2.0572 - mse: 8.6616 - val_loss: 6.8822 - val_mae: 2.2255 - val_mse: 6.8822\n",
      "Epoch 159/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.6418 - mae: 2.0504 - mse: 8.6418 - val_loss: 6.9682 - val_mae: 2.2522 - val_mse: 6.9682\n",
      "Epoch 160/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5842 - mae: 2.0472 - mse: 8.5842 - val_loss: 6.8559 - val_mae: 2.2062 - val_mse: 6.8559\n",
      "Epoch 161/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5813 - mae: 2.0508 - mse: 8.5813 - val_loss: 6.9045 - val_mae: 2.2352 - val_mse: 6.9045\n",
      "Epoch 162/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5542 - mae: 2.0527 - mse: 8.5542 - val_loss: 6.8833 - val_mae: 2.1928 - val_mse: 6.8833\n",
      "Epoch 163/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5962 - mae: 2.0678 - mse: 8.5962 - val_loss: 6.8857 - val_mae: 2.1985 - val_mse: 6.8857\n",
      "Epoch 164/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4767 - mae: 2.0425 - mse: 8.4767 - val_loss: 7.0278 - val_mae: 2.2734 - val_mse: 7.0278\n",
      "Epoch 165/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4727 - mae: 2.0321 - mse: 8.4727 - val_loss: 7.0113 - val_mae: 2.2753 - val_mse: 7.0113\n",
      "Epoch 166/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4759 - mae: 2.0375 - mse: 8.4759 - val_loss: 6.7776 - val_mae: 2.2164 - val_mse: 6.7776\n",
      "Epoch 167/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.4135 - mae: 2.0303 - mse: 8.4135 - val_loss: 6.8959 - val_mae: 2.2477 - val_mse: 6.8959\n",
      "Epoch 168/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3985 - mae: 2.0237 - mse: 8.3985 - val_loss: 6.6620 - val_mae: 2.2085 - val_mse: 6.6620\n",
      "Epoch 169/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3579 - mae: 2.0178 - mse: 8.3579 - val_loss: 6.6752 - val_mae: 2.2100 - val_mse: 6.6752\n",
      "Epoch 170/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3490 - mae: 2.0177 - mse: 8.3490 - val_loss: 6.5792 - val_mae: 2.1856 - val_mse: 6.5792\n",
      "Epoch 171/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3174 - mae: 2.0211 - mse: 8.3174 - val_loss: 6.4875 - val_mae: 2.1642 - val_mse: 6.4875\n",
      "Epoch 172/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3493 - mae: 2.0168 - mse: 8.3493 - val_loss: 6.5925 - val_mae: 2.2127 - val_mse: 6.5925\n",
      "Epoch 173/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.2530 - mae: 2.0040 - mse: 8.2530 - val_loss: 6.4601 - val_mae: 2.1693 - val_mse: 6.4601\n",
      "Epoch 174/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.2483 - mae: 2.0076 - mse: 8.2483 - val_loss: 6.4911 - val_mae: 2.1783 - val_mse: 6.4911\n",
      "Epoch 175/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.2083 - mae: 2.0046 - mse: 8.2083 - val_loss: 6.4265 - val_mae: 2.1811 - val_mse: 6.4265\n",
      "Epoch 176/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.2257 - mae: 1.9942 - mse: 8.2257 - val_loss: 6.4902 - val_mae: 2.2078 - val_mse: 6.4902\n",
      "Epoch 177/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.3271 - mae: 2.0191 - mse: 8.3271 - val_loss: 6.2654 - val_mae: 2.1326 - val_mse: 6.2654\n",
      "Epoch 178/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.1225 - mae: 1.9942 - mse: 8.1225 - val_loss: 6.4060 - val_mae: 2.1815 - val_mse: 6.4060\n",
      "Epoch 179/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.1266 - mae: 1.9870 - mse: 8.1266 - val_loss: 6.4089 - val_mae: 2.1881 - val_mse: 6.4089\n",
      "Epoch 180/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.1128 - mae: 1.9839 - mse: 8.1128 - val_loss: 6.3274 - val_mae: 2.1661 - val_mse: 6.3274\n",
      "Epoch 181/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.0604 - mae: 1.9818 - mse: 8.0604 - val_loss: 6.2481 - val_mae: 2.1373 - val_mse: 6.2481\n",
      "Epoch 182/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.0778 - mae: 1.9874 - mse: 8.0778 - val_loss: 6.3668 - val_mae: 2.1694 - val_mse: 6.3668\n",
      "Epoch 183/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.0274 - mae: 1.9827 - mse: 8.0274 - val_loss: 6.2991 - val_mae: 2.1475 - val_mse: 6.2991\n",
      "Epoch 184/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.0128 - mae: 1.9772 - mse: 8.0128 - val_loss: 6.4126 - val_mae: 2.1755 - val_mse: 6.4126\n",
      "Epoch 185/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.9770 - mae: 1.9770 - mse: 7.9770 - val_loss: 6.2426 - val_mae: 2.1281 - val_mse: 6.2426\n",
      "Epoch 186/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.9744 - mae: 1.9761 - mse: 7.9744 - val_loss: 6.3028 - val_mae: 2.1479 - val_mse: 6.3028\n",
      "Epoch 187/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.9467 - mae: 1.9724 - mse: 7.9467 - val_loss: 6.2766 - val_mae: 2.1426 - val_mse: 6.2766\n",
      "Epoch 188/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.9471 - mae: 1.9666 - mse: 7.9471 - val_loss: 6.3834 - val_mae: 2.1829 - val_mse: 6.3834\n",
      "Epoch 189/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.9196 - mae: 1.9641 - mse: 7.9196 - val_loss: 6.1031 - val_mae: 2.1051 - val_mse: 6.1031\n",
      "Epoch 190/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.8969 - mae: 1.9687 - mse: 7.8969 - val_loss: 6.0680 - val_mae: 2.1052 - val_mse: 6.0680\n",
      "Epoch 191/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.8842 - mae: 1.9647 - mse: 7.8842 - val_loss: 6.2276 - val_mae: 2.1446 - val_mse: 6.2276\n",
      "Epoch 192/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.8740 - mae: 1.9703 - mse: 7.8740 - val_loss: 5.9554 - val_mae: 2.0594 - val_mse: 5.9554\n",
      "Epoch 193/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.8448 - mae: 1.9529 - mse: 7.8448 - val_loss: 6.2321 - val_mae: 2.1481 - val_mse: 6.2321\n",
      "Epoch 194/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.7883 - mae: 1.9473 - mse: 7.7883 - val_loss: 6.1829 - val_mae: 2.1376 - val_mse: 6.1829\n",
      "Epoch 195/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.7864 - mae: 1.9541 - mse: 7.7864 - val_loss: 6.0995 - val_mae: 2.1175 - val_mse: 6.0995\n",
      "Epoch 196/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.7592 - mae: 1.9510 - mse: 7.7592 - val_loss: 6.1497 - val_mae: 2.1286 - val_mse: 6.1497\n",
      "Epoch 197/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.7436 - mae: 1.9458 - mse: 7.7436 - val_loss: 6.0547 - val_mae: 2.1018 - val_mse: 6.0547\n",
      "Epoch 198/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.7482 - mae: 1.9459 - mse: 7.7482 - val_loss: 6.1611 - val_mae: 2.1387 - val_mse: 6.1611\n",
      "Epoch 199/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.6760 - mae: 1.9371 - mse: 7.6760 - val_loss: 6.0177 - val_mae: 2.1088 - val_mse: 6.0177\n",
      "Epoch 200/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.6886 - mae: 1.9431 - mse: 7.6886 - val_loss: 5.9777 - val_mae: 2.0949 - val_mse: 5.9777\n",
      "Epoch 201/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.6757 - mae: 1.9374 - mse: 7.6757 - val_loss: 5.9599 - val_mae: 2.0917 - val_mse: 5.9599\n",
      "Epoch 202/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.6577 - mae: 1.9321 - mse: 7.6577 - val_loss: 5.9320 - val_mae: 2.0762 - val_mse: 5.9320\n",
      "Epoch 203/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.5844 - mae: 1.9230 - mse: 7.5844 - val_loss: 6.0706 - val_mae: 2.1175 - val_mse: 6.0706\n",
      "Epoch 204/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.6135 - mae: 1.9264 - mse: 7.6135 - val_loss: 6.0492 - val_mae: 2.1106 - val_mse: 6.0492\n",
      "Epoch 205/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.5800 - mae: 1.9225 - mse: 7.5800 - val_loss: 5.9588 - val_mae: 2.0879 - val_mse: 5.9588\n",
      "Epoch 206/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.5665 - mae: 1.9195 - mse: 7.5665 - val_loss: 5.9062 - val_mae: 2.0804 - val_mse: 5.9062\n",
      "Epoch 207/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.5477 - mae: 1.9189 - mse: 7.5477 - val_loss: 5.8609 - val_mae: 2.0604 - val_mse: 5.8609\n",
      "Epoch 208/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.5357 - mae: 1.9168 - mse: 7.5357 - val_loss: 5.8019 - val_mae: 2.0556 - val_mse: 5.8019\n",
      "Epoch 209/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.5035 - mae: 1.9127 - mse: 7.5035 - val_loss: 5.8679 - val_mae: 2.0751 - val_mse: 5.8679\n",
      "Epoch 210/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4765 - mae: 1.9102 - mse: 7.4765 - val_loss: 5.8045 - val_mae: 2.0558 - val_mse: 5.8045\n",
      "Epoch 211/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4598 - mae: 1.9080 - mse: 7.4598 - val_loss: 5.9433 - val_mae: 2.0828 - val_mse: 5.9433\n",
      "Epoch 212/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4624 - mae: 1.9062 - mse: 7.4624 - val_loss: 5.9033 - val_mae: 2.0734 - val_mse: 5.9033\n",
      "Epoch 213/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4402 - mae: 1.9015 - mse: 7.4402 - val_loss: 5.8497 - val_mae: 2.0686 - val_mse: 5.8497\n",
      "Epoch 214/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4239 - mae: 1.9008 - mse: 7.4239 - val_loss: 5.9120 - val_mae: 2.0810 - val_mse: 5.9120\n",
      "Epoch 215/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4119 - mae: 1.8994 - mse: 7.4119 - val_loss: 5.7520 - val_mae: 2.0410 - val_mse: 5.7520\n",
      "Epoch 216/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3902 - mae: 1.8992 - mse: 7.3902 - val_loss: 5.7933 - val_mae: 2.0555 - val_mse: 5.7933\n",
      "Epoch 217/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3936 - mae: 1.8957 - mse: 7.3936 - val_loss: 5.6929 - val_mae: 2.0263 - val_mse: 5.6929\n",
      "Epoch 218/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3644 - mae: 1.8876 - mse: 7.3644 - val_loss: 5.9469 - val_mae: 2.0919 - val_mse: 5.9469\n",
      "Epoch 219/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3493 - mae: 1.8889 - mse: 7.3493 - val_loss: 5.7474 - val_mae: 2.0377 - val_mse: 5.7474\n",
      "Epoch 220/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3430 - mae: 1.8915 - mse: 7.3430 - val_loss: 5.6846 - val_mae: 2.0315 - val_mse: 5.6846\n",
      "Epoch 221/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3218 - mae: 1.8879 - mse: 7.3218 - val_loss: 5.7317 - val_mae: 2.0392 - val_mse: 5.7317\n",
      "Epoch 222/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3135 - mae: 1.8877 - mse: 7.3135 - val_loss: 5.7950 - val_mae: 2.0608 - val_mse: 5.7950\n",
      "Epoch 223/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3068 - mae: 1.8914 - mse: 7.3068 - val_loss: 5.5608 - val_mae: 1.9927 - val_mse: 5.5608\n",
      "Epoch 224/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.3144 - mae: 1.8819 - mse: 7.3144 - val_loss: 5.7799 - val_mae: 2.0581 - val_mse: 5.7799\n",
      "Epoch 225/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.2556 - mae: 1.8801 - mse: 7.2556 - val_loss: 5.6272 - val_mae: 2.0209 - val_mse: 5.6272\n",
      "Epoch 226/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.2248 - mae: 1.8777 - mse: 7.2248 - val_loss: 5.5580 - val_mae: 2.0053 - val_mse: 5.5580\n",
      "Epoch 227/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.2364 - mae: 1.8791 - mse: 7.2364 - val_loss: 5.4678 - val_mae: 1.9855 - val_mse: 5.4678\n",
      "Epoch 228/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.2858 - mae: 1.8773 - mse: 7.2858 - val_loss: 5.7459 - val_mae: 2.0480 - val_mse: 5.7459\n",
      "Epoch 229/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.1487 - mae: 1.8693 - mse: 7.1487 - val_loss: 5.4474 - val_mae: 1.9587 - val_mse: 5.4474\n",
      "Epoch 230/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.1916 - mae: 1.8806 - mse: 7.1916 - val_loss: 5.4626 - val_mae: 1.9555 - val_mse: 5.4626\n",
      "Epoch 231/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.1697 - mae: 1.8708 - mse: 7.1697 - val_loss: 5.6267 - val_mae: 2.0130 - val_mse: 5.6267\n",
      "Epoch 232/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.2333 - mae: 1.8758 - mse: 7.2333 - val_loss: 5.6377 - val_mae: 2.0208 - val_mse: 5.6377\n",
      "Epoch 233/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.1154 - mae: 1.8612 - mse: 7.1154 - val_loss: 5.3466 - val_mae: 1.9399 - val_mse: 5.3466\n",
      "Epoch 234/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.1453 - mae: 1.8676 - mse: 7.1453 - val_loss: 5.4722 - val_mae: 1.9782 - val_mse: 5.4722\n",
      "Epoch 235/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0978 - mae: 1.8711 - mse: 7.0978 - val_loss: 5.3907 - val_mae: 1.9466 - val_mse: 5.3907\n",
      "Epoch 236/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0533 - mae: 1.8569 - mse: 7.0533 - val_loss: 5.6102 - val_mae: 2.0046 - val_mse: 5.6102\n",
      "Epoch 237/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0966 - mae: 1.8518 - mse: 7.0966 - val_loss: 5.6169 - val_mae: 2.0123 - val_mse: 5.6169\n",
      "Epoch 238/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0394 - mae: 1.8486 - mse: 7.0394 - val_loss: 5.5198 - val_mae: 1.9808 - val_mse: 5.5198\n",
      "Epoch 239/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0514 - mae: 1.8535 - mse: 7.0514 - val_loss: 5.5783 - val_mae: 1.9979 - val_mse: 5.5783\n",
      "Epoch 240/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0185 - mae: 1.8464 - mse: 7.0185 - val_loss: 5.4618 - val_mae: 1.9711 - val_mse: 5.4618\n",
      "Epoch 241/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0254 - mae: 1.8579 - mse: 7.0254 - val_loss: 5.1807 - val_mae: 1.8923 - val_mse: 5.1807\n",
      "Epoch 242/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.0599 - mae: 1.8581 - mse: 7.0599 - val_loss: 5.5684 - val_mae: 1.9984 - val_mse: 5.5684\n",
      "Epoch 243/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9741 - mae: 1.8388 - mse: 6.9741 - val_loss: 5.4969 - val_mae: 1.9719 - val_mse: 5.4969\n",
      "Epoch 244/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9565 - mae: 1.8365 - mse: 6.9565 - val_loss: 5.4838 - val_mae: 1.9759 - val_mse: 5.4838\n",
      "Epoch 245/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9859 - mae: 1.8331 - mse: 6.9859 - val_loss: 5.5090 - val_mae: 1.9845 - val_mse: 5.5090\n",
      "Epoch 246/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9032 - mae: 1.8245 - mse: 6.9032 - val_loss: 5.3387 - val_mae: 1.9495 - val_mse: 5.3387\n",
      "Epoch 247/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9745 - mae: 1.8544 - mse: 6.9745 - val_loss: 5.1683 - val_mae: 1.8958 - val_mse: 5.1683\n",
      "Epoch 248/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.9406 - mae: 1.8374 - mse: 6.9406 - val_loss: 5.5811 - val_mae: 1.9983 - val_mse: 5.5811\n",
      "Epoch 249/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8588 - mae: 1.8244 - mse: 6.8588 - val_loss: 5.3206 - val_mae: 1.9313 - val_mse: 5.3206\n",
      "Epoch 250/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8585 - mae: 1.8341 - mse: 6.8585 - val_loss: 5.2922 - val_mae: 1.9237 - val_mse: 5.2922\n",
      "Epoch 251/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8305 - mae: 1.8194 - mse: 6.8305 - val_loss: 5.4218 - val_mae: 1.9656 - val_mse: 5.4218\n",
      "Epoch 252/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8392 - mae: 1.8219 - mse: 6.8392 - val_loss: 5.4226 - val_mae: 1.9620 - val_mse: 5.4226\n",
      "Epoch 253/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8009 - mae: 1.8120 - mse: 6.8009 - val_loss: 5.4860 - val_mae: 1.9829 - val_mse: 5.4860\n",
      "Epoch 254/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8153 - mae: 1.8180 - mse: 6.8153 - val_loss: 5.2909 - val_mae: 1.9397 - val_mse: 5.2909\n",
      "Epoch 255/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.7899 - mae: 1.8096 - mse: 6.7899 - val_loss: 5.3437 - val_mae: 1.9507 - val_mse: 5.3437\n",
      "Epoch 256/1000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.7628 - mae: 1.8082 - mse: 6.7628 - val_loss: 5.2325 - val_mae: 1.9210 - val_mse: 5.2325\n",
      "Epoch 257/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.7437 - mae: 1.8079 - mse: 6.7437 - val_loss: 5.1793 - val_mae: 1.9084 - val_mse: 5.1793\n",
      "Epoch 258/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.7343 - mae: 1.8054 - mse: 6.7343 - val_loss: 5.3515 - val_mae: 1.9453 - val_mse: 5.3515\n",
      "Epoch 259/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.7222 - mae: 1.8038 - mse: 6.7222 - val_loss: 5.1849 - val_mae: 1.9075 - val_mse: 5.1849\n",
      "Epoch 260/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.7061 - mae: 1.8089 - mse: 6.7061 - val_loss: 5.1427 - val_mae: 1.8926 - val_mse: 5.1427\n",
      "Epoch 261/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.7052 - mae: 1.8006 - mse: 6.7052 - val_loss: 5.3524 - val_mae: 1.9485 - val_mse: 5.3524\n",
      "Epoch 262/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6901 - mae: 1.7956 - mse: 6.6901 - val_loss: 5.1965 - val_mae: 1.9106 - val_mse: 5.1965\n",
      "Epoch 263/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6821 - mae: 1.7978 - mse: 6.6821 - val_loss: 5.2385 - val_mae: 1.9153 - val_mse: 5.2385\n",
      "Epoch 264/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6404 - mae: 1.7924 - mse: 6.6404 - val_loss: 5.3847 - val_mae: 1.9514 - val_mse: 5.3847\n",
      "Epoch 265/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6921 - mae: 1.7901 - mse: 6.6921 - val_loss: 5.4536 - val_mae: 1.9647 - val_mse: 5.4536\n",
      "Epoch 266/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6554 - mae: 1.7884 - mse: 6.6554 - val_loss: 5.0150 - val_mae: 1.8712 - val_mse: 5.0150\n",
      "Epoch 267/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6299 - mae: 1.7950 - mse: 6.6299 - val_loss: 5.0078 - val_mae: 1.8636 - val_mse: 5.0078\n",
      "Epoch 268/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6381 - mae: 1.7929 - mse: 6.6381 - val_loss: 5.1442 - val_mae: 1.8975 - val_mse: 5.1442\n",
      "Epoch 269/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5944 - mae: 1.7833 - mse: 6.5944 - val_loss: 5.2580 - val_mae: 1.9217 - val_mse: 5.2580\n",
      "Epoch 270/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5932 - mae: 1.7817 - mse: 6.5932 - val_loss: 5.1547 - val_mae: 1.9000 - val_mse: 5.1547\n",
      "Epoch 271/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5557 - mae: 1.7794 - mse: 6.5557 - val_loss: 5.1642 - val_mae: 1.8968 - val_mse: 5.1642\n",
      "Epoch 272/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5716 - mae: 1.7845 - mse: 6.5716 - val_loss: 5.2081 - val_mae: 1.9036 - val_mse: 5.2081\n",
      "Epoch 273/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5959 - mae: 1.7827 - mse: 6.5959 - val_loss: 5.2160 - val_mae: 1.9321 - val_mse: 5.2160\n",
      "Epoch 274/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5849 - mae: 1.7774 - mse: 6.5849 - val_loss: 5.2409 - val_mae: 1.9093 - val_mse: 5.2409\n",
      "Epoch 275/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5341 - mae: 1.7741 - mse: 6.5341 - val_loss: 5.2208 - val_mae: 1.9280 - val_mse: 5.2208\n",
      "Epoch 276/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5209 - mae: 1.7774 - mse: 6.5209 - val_loss: 5.0319 - val_mae: 1.8804 - val_mse: 5.0319\n",
      "Epoch 277/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5099 - mae: 1.7801 - mse: 6.5099 - val_loss: 5.2594 - val_mae: 1.9174 - val_mse: 5.2594\n",
      "Epoch 278/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.5105 - mae: 1.7710 - mse: 6.5105 - val_loss: 5.1431 - val_mae: 1.9038 - val_mse: 5.1431\n",
      "Epoch 279/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4613 - mae: 1.7675 - mse: 6.4613 - val_loss: 5.0433 - val_mae: 1.8699 - val_mse: 5.0433\n",
      "Epoch 280/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4583 - mae: 1.7697 - mse: 6.4583 - val_loss: 5.0757 - val_mae: 1.8919 - val_mse: 5.0757\n",
      "Epoch 281/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4472 - mae: 1.7645 - mse: 6.4472 - val_loss: 5.2165 - val_mae: 1.8984 - val_mse: 5.2165\n",
      "Epoch 282/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4788 - mae: 1.7599 - mse: 6.4788 - val_loss: 5.2331 - val_mae: 1.9178 - val_mse: 5.2331\n",
      "Epoch 283/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3911 - mae: 1.7541 - mse: 6.3911 - val_loss: 5.0478 - val_mae: 1.8787 - val_mse: 5.0478\n",
      "Epoch 284/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4164 - mae: 1.7632 - mse: 6.4164 - val_loss: 5.1345 - val_mae: 1.8958 - val_mse: 5.1345\n",
      "Epoch 285/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4252 - mae: 1.7579 - mse: 6.4252 - val_loss: 5.2921 - val_mae: 1.9122 - val_mse: 5.2921\n",
      "Epoch 286/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4275 - mae: 1.7583 - mse: 6.4275 - val_loss: 4.9455 - val_mae: 1.8350 - val_mse: 4.9455\n",
      "Epoch 287/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3582 - mae: 1.7544 - mse: 6.3582 - val_loss: 5.1865 - val_mae: 1.9085 - val_mse: 5.1865\n",
      "Epoch 288/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3461 - mae: 1.7394 - mse: 6.3461 - val_loss: 5.2926 - val_mae: 1.9295 - val_mse: 5.2926\n",
      "Epoch 289/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.4309 - mae: 1.7567 - mse: 6.4309 - val_loss: 5.0748 - val_mae: 1.8912 - val_mse: 5.0748\n",
      "Epoch 290/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3818 - mae: 1.7505 - mse: 6.3818 - val_loss: 5.1138 - val_mae: 1.8703 - val_mse: 5.1138\n",
      "Epoch 291/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3744 - mae: 1.7613 - mse: 6.3744 - val_loss: 4.9408 - val_mae: 1.8550 - val_mse: 4.9408\n",
      "Epoch 292/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3515 - mae: 1.7504 - mse: 6.3515 - val_loss: 5.3856 - val_mae: 1.9384 - val_mse: 5.3856\n",
      "Epoch 293/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3204 - mae: 1.7415 - mse: 6.3204 - val_loss: 5.1481 - val_mae: 1.8824 - val_mse: 5.1481\n",
      "Epoch 294/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2867 - mae: 1.7352 - mse: 6.2867 - val_loss: 4.9196 - val_mae: 1.8454 - val_mse: 4.9196\n",
      "Epoch 295/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2860 - mae: 1.7433 - mse: 6.2860 - val_loss: 5.0379 - val_mae: 1.8608 - val_mse: 5.0379\n",
      "Epoch 296/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2523 - mae: 1.7289 - mse: 6.2523 - val_loss: 5.1750 - val_mae: 1.8929 - val_mse: 5.1750\n",
      "Epoch 297/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2445 - mae: 1.7307 - mse: 6.2445 - val_loss: 5.1165 - val_mae: 1.8936 - val_mse: 5.1165\n",
      "Epoch 298/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2846 - mae: 1.7410 - mse: 6.2846 - val_loss: 4.9512 - val_mae: 1.8350 - val_mse: 4.9512\n",
      "Epoch 299/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2289 - mae: 1.7225 - mse: 6.2289 - val_loss: 5.1770 - val_mae: 1.8934 - val_mse: 5.1770\n",
      "Epoch 300/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2397 - mae: 1.7253 - mse: 6.2397 - val_loss: 5.0476 - val_mae: 1.8674 - val_mse: 5.0476\n",
      "Epoch 301/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3073 - mae: 1.7298 - mse: 6.3073 - val_loss: 5.0258 - val_mae: 1.8714 - val_mse: 5.0258\n",
      "Epoch 302/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2198 - mae: 1.7291 - mse: 6.2198 - val_loss: 5.0500 - val_mae: 1.8404 - val_mse: 5.0500\n",
      "Epoch 303/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.2523 - mae: 1.7435 - mse: 6.2523 - val_loss: 4.8688 - val_mae: 1.8232 - val_mse: 4.8688\n",
      "Epoch 304/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2005 - mae: 1.7244 - mse: 6.2005 - val_loss: 5.1442 - val_mae: 1.8827 - val_mse: 5.1442\n",
      "Epoch 305/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1743 - mae: 1.7232 - mse: 6.1743 - val_loss: 4.8528 - val_mae: 1.8262 - val_mse: 4.8528\n",
      "Epoch 306/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1654 - mae: 1.7247 - mse: 6.1654 - val_loss: 5.0918 - val_mae: 1.8748 - val_mse: 5.0918\n",
      "Epoch 307/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.2167 - mae: 1.7167 - mse: 6.2167 - val_loss: 5.1589 - val_mae: 1.8924 - val_mse: 5.1589\n",
      "Epoch 308/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1206 - mae: 1.7172 - mse: 6.1206 - val_loss: 4.8536 - val_mae: 1.8310 - val_mse: 4.8536\n",
      "Epoch 309/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1518 - mae: 1.7241 - mse: 6.1518 - val_loss: 5.1665 - val_mae: 1.8934 - val_mse: 5.1665\n",
      "Epoch 310/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1280 - mae: 1.7151 - mse: 6.1280 - val_loss: 5.0876 - val_mae: 1.8748 - val_mse: 5.0876\n",
      "Epoch 311/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0811 - mae: 1.7070 - mse: 6.0811 - val_loss: 5.1327 - val_mae: 1.8778 - val_mse: 5.1327\n",
      "Epoch 312/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0965 - mae: 1.7034 - mse: 6.0965 - val_loss: 5.3022 - val_mae: 1.9080 - val_mse: 5.3022\n",
      "Epoch 313/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0694 - mae: 1.6957 - mse: 6.0694 - val_loss: 5.0024 - val_mae: 1.8464 - val_mse: 5.0024\n",
      "Epoch 314/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1048 - mae: 1.7051 - mse: 6.1048 - val_loss: 5.2018 - val_mae: 1.8909 - val_mse: 5.2018\n",
      "Epoch 315/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0836 - mae: 1.6975 - mse: 6.0836 - val_loss: 5.1223 - val_mae: 1.8682 - val_mse: 5.1223\n",
      "Epoch 316/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0459 - mae: 1.6965 - mse: 6.0459 - val_loss: 4.9624 - val_mae: 1.8198 - val_mse: 4.9624\n",
      "Epoch 317/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0347 - mae: 1.7045 - mse: 6.0347 - val_loss: 5.0312 - val_mae: 1.8520 - val_mse: 5.0312\n",
      "Epoch 318/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0097 - mae: 1.7011 - mse: 6.0097 - val_loss: 5.1876 - val_mae: 1.8699 - val_mse: 5.1876\n",
      "Epoch 319/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9978 - mae: 1.6931 - mse: 5.9978 - val_loss: 4.8797 - val_mae: 1.8237 - val_mse: 4.8797\n",
      "Epoch 320/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0278 - mae: 1.6926 - mse: 6.0278 - val_loss: 5.0826 - val_mae: 1.8636 - val_mse: 5.0826\n",
      "Epoch 321/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0265 - mae: 1.7012 - mse: 6.0265 - val_loss: 4.9757 - val_mae: 1.8371 - val_mse: 4.9757\n",
      "Epoch 322/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.0384 - mae: 1.6887 - mse: 6.0384 - val_loss: 5.1495 - val_mae: 1.8742 - val_mse: 5.1495\n",
      "Epoch 323/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9490 - mae: 1.6861 - mse: 5.9490 - val_loss: 4.9478 - val_mae: 1.8410 - val_mse: 4.9478\n",
      "Epoch 324/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9575 - mae: 1.6918 - mse: 5.9575 - val_loss: 4.9516 - val_mae: 1.8394 - val_mse: 4.9516\n",
      "Epoch 325/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9457 - mae: 1.6859 - mse: 5.9457 - val_loss: 5.0284 - val_mae: 1.8557 - val_mse: 5.0284\n",
      "Epoch 326/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9416 - mae: 1.6807 - mse: 5.9416 - val_loss: 4.9492 - val_mae: 1.8230 - val_mse: 4.9492\n",
      "Epoch 327/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9134 - mae: 1.6768 - mse: 5.9134 - val_loss: 5.0663 - val_mae: 1.8516 - val_mse: 5.0663\n",
      "Epoch 328/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9520 - mae: 1.6735 - mse: 5.9520 - val_loss: 5.2773 - val_mae: 1.8957 - val_mse: 5.2773\n",
      "Epoch 329/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9788 - mae: 1.6929 - mse: 5.9788 - val_loss: 4.8229 - val_mae: 1.7918 - val_mse: 4.8229\n",
      "Epoch 330/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9401 - mae: 1.6935 - mse: 5.9401 - val_loss: 5.2228 - val_mae: 1.8752 - val_mse: 5.2228\n",
      "Epoch 331/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8590 - mae: 1.6708 - mse: 5.8590 - val_loss: 5.0400 - val_mae: 1.8501 - val_mse: 5.0400\n",
      "Epoch 332/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8726 - mae: 1.6671 - mse: 5.8726 - val_loss: 5.1085 - val_mae: 1.8621 - val_mse: 5.1085\n",
      "Epoch 333/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8778 - mae: 1.6717 - mse: 5.8778 - val_loss: 4.9179 - val_mae: 1.8091 - val_mse: 4.9179\n",
      "Epoch 334/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8638 - mae: 1.6716 - mse: 5.8638 - val_loss: 4.9771 - val_mae: 1.8284 - val_mse: 4.9771\n",
      "Epoch 335/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9135 - mae: 1.6832 - mse: 5.9135 - val_loss: 4.9015 - val_mae: 1.8213 - val_mse: 4.9015\n",
      "Epoch 336/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8545 - mae: 1.6724 - mse: 5.8545 - val_loss: 5.3081 - val_mae: 1.8906 - val_mse: 5.3081\n",
      "Epoch 337/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9095 - mae: 1.6746 - mse: 5.9095 - val_loss: 4.9061 - val_mae: 1.8078 - val_mse: 4.9061\n",
      "Epoch 338/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8324 - mae: 1.6665 - mse: 5.8324 - val_loss: 5.0866 - val_mae: 1.8548 - val_mse: 5.0866\n",
      "Epoch 339/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7975 - mae: 1.6557 - mse: 5.7975 - val_loss: 4.8678 - val_mae: 1.8067 - val_mse: 4.8678\n",
      "Epoch 340/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8193 - mae: 1.6548 - mse: 5.8193 - val_loss: 5.0407 - val_mae: 1.8416 - val_mse: 5.0407\n",
      "Epoch 341/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7762 - mae: 1.6597 - mse: 5.7762 - val_loss: 4.7833 - val_mae: 1.7757 - val_mse: 4.7833\n",
      "Epoch 342/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 5.8177 - mae: 1.6712 - mse: 5.8177 - val_loss: 4.9771 - val_mae: 1.8307 - val_mse: 4.9771\n",
      "Epoch 343/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7735 - mae: 1.6652 - mse: 5.7735 - val_loss: 5.1779 - val_mae: 1.8632 - val_mse: 5.1779\n",
      "Epoch 344/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7726 - mae: 1.6609 - mse: 5.7726 - val_loss: 4.8637 - val_mae: 1.8140 - val_mse: 4.8637\n",
      "Epoch 345/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7454 - mae: 1.6576 - mse: 5.7454 - val_loss: 5.1638 - val_mae: 1.8762 - val_mse: 5.1638\n",
      "Epoch 346/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7840 - mae: 1.6553 - mse: 5.7840 - val_loss: 5.1455 - val_mae: 1.8606 - val_mse: 5.1455\n",
      "Epoch 347/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7336 - mae: 1.6495 - mse: 5.7336 - val_loss: 4.7176 - val_mae: 1.7704 - val_mse: 4.7176\n",
      "Epoch 348/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7625 - mae: 1.6605 - mse: 5.7625 - val_loss: 4.9495 - val_mae: 1.8196 - val_mse: 4.9495\n",
      "Epoch 349/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7594 - mae: 1.6523 - mse: 5.7594 - val_loss: 5.1696 - val_mae: 1.8604 - val_mse: 5.1696\n",
      "Epoch 350/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.7276 - mae: 1.6484 - mse: 5.7276 - val_loss: 4.8453 - val_mae: 1.7923 - val_mse: 4.8453\n",
      "Epoch 351/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7104 - mae: 1.6554 - mse: 5.7104 - val_loss: 5.0409 - val_mae: 1.8375 - val_mse: 5.0409\n",
      "Epoch 352/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7403 - mae: 1.6523 - mse: 5.7403 - val_loss: 5.2402 - val_mae: 1.8719 - val_mse: 5.2402\n",
      "Epoch 353/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7728 - mae: 1.6549 - mse: 5.7728 - val_loss: 4.9156 - val_mae: 1.8136 - val_mse: 4.9156\n",
      "Epoch 354/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6855 - mae: 1.6435 - mse: 5.6855 - val_loss: 5.2503 - val_mae: 1.8757 - val_mse: 5.2503\n",
      "Epoch 355/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.6843 - mae: 1.6387 - mse: 5.6843 - val_loss: 5.0208 - val_mae: 1.8289 - val_mse: 5.0208\n",
      "Epoch 356/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6883 - mae: 1.6449 - mse: 5.6883 - val_loss: 4.8383 - val_mae: 1.7884 - val_mse: 4.8383\n",
      "Epoch 357/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6328 - mae: 1.6354 - mse: 5.6328 - val_loss: 5.1621 - val_mae: 1.8496 - val_mse: 5.1621\n",
      "Epoch 358/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6396 - mae: 1.6436 - mse: 5.6396 - val_loss: 4.9549 - val_mae: 1.8166 - val_mse: 4.9549\n",
      "Epoch 359/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6322 - mae: 1.6388 - mse: 5.6322 - val_loss: 4.9410 - val_mae: 1.8199 - val_mse: 4.9410\n",
      "Epoch 360/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6590 - mae: 1.6444 - mse: 5.6590 - val_loss: 5.0899 - val_mae: 1.8502 - val_mse: 5.0899\n",
      "Epoch 361/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6881 - mae: 1.6489 - mse: 5.6881 - val_loss: 4.9010 - val_mae: 1.8103 - val_mse: 4.9010\n",
      "Epoch 362/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7752 - mae: 1.6737 - mse: 5.7752 - val_loss: 5.1163 - val_mae: 1.8475 - val_mse: 5.1163\n",
      "Epoch 363/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6409 - mae: 1.6389 - mse: 5.6409 - val_loss: 4.9682 - val_mae: 1.8330 - val_mse: 4.9682\n",
      "Epoch 364/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6313 - mae: 1.6371 - mse: 5.6313 - val_loss: 4.9670 - val_mae: 1.8123 - val_mse: 4.9670\n",
      "Epoch 365/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6671 - mae: 1.6514 - mse: 5.6671 - val_loss: 5.0455 - val_mae: 1.8227 - val_mse: 5.0455\n",
      "Epoch 366/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6141 - mae: 1.6341 - mse: 5.6141 - val_loss: 4.9048 - val_mae: 1.8145 - val_mse: 4.9048\n",
      "Epoch 367/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7113 - mae: 1.6542 - mse: 5.7113 - val_loss: 5.1322 - val_mae: 1.8448 - val_mse: 5.1322\n",
      "Epoch 368/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6276 - mae: 1.6373 - mse: 5.6276 - val_loss: 4.8401 - val_mae: 1.7890 - val_mse: 4.8401\n",
      "Epoch 369/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5928 - mae: 1.6318 - mse: 5.5928 - val_loss: 5.0453 - val_mae: 1.8354 - val_mse: 5.0453\n",
      "Epoch 370/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.6049 - mae: 1.6397 - mse: 5.6049 - val_loss: 5.0150 - val_mae: 1.8234 - val_mse: 5.0150\n",
      "Epoch 371/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5976 - mae: 1.6323 - mse: 5.5976 - val_loss: 5.2619 - val_mae: 1.8796 - val_mse: 5.2619\n",
      "Epoch 372/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5609 - mae: 1.6237 - mse: 5.5609 - val_loss: 4.9019 - val_mae: 1.8000 - val_mse: 4.9019\n",
      "Epoch 373/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5240 - mae: 1.6178 - mse: 5.5240 - val_loss: 4.9772 - val_mae: 1.8166 - val_mse: 4.9772\n",
      "Epoch 374/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5170 - mae: 1.6164 - mse: 5.5170 - val_loss: 4.8212 - val_mae: 1.7888 - val_mse: 4.8212\n",
      "Epoch 375/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5361 - mae: 1.6176 - mse: 5.5361 - val_loss: 4.9929 - val_mae: 1.8182 - val_mse: 4.9929\n",
      "Epoch 376/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5282 - mae: 1.6201 - mse: 5.5282 - val_loss: 5.0793 - val_mae: 1.8273 - val_mse: 5.0793\n",
      "Epoch 377/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.5612 - mae: 1.6236 - mse: 5.5612 - val_loss: 4.8513 - val_mae: 1.7807 - val_mse: 4.8513\n",
      "Epoch 378/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4938 - mae: 1.6103 - mse: 5.4938 - val_loss: 5.1339 - val_mae: 1.8424 - val_mse: 5.1339\n",
      "Epoch 379/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4916 - mae: 1.6100 - mse: 5.4916 - val_loss: 4.9403 - val_mae: 1.8036 - val_mse: 4.9403\n",
      "Epoch 380/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4775 - mae: 1.6144 - mse: 5.4775 - val_loss: 4.9059 - val_mae: 1.7922 - val_mse: 4.9059\n",
      "Epoch 381/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4821 - mae: 1.6166 - mse: 5.4821 - val_loss: 4.9400 - val_mae: 1.8020 - val_mse: 4.9400\n",
      "Epoch 382/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.5382 - mae: 1.6191 - mse: 5.5382 - val_loss: 5.1124 - val_mae: 1.8325 - val_mse: 5.1124\n",
      "Epoch 383/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4540 - mae: 1.6052 - mse: 5.4540 - val_loss: 4.8186 - val_mae: 1.7677 - val_mse: 4.8186\n",
      "Epoch 384/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4756 - mae: 1.6157 - mse: 5.4756 - val_loss: 4.9746 - val_mae: 1.8016 - val_mse: 4.9746\n",
      "Epoch 385/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 5.4926 - mae: 1.6141 - mse: 5.4926 - val_loss: 4.8318 - val_mae: 1.7839 - val_mse: 4.8318\n",
      "Epoch 386/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4601 - mae: 1.6083 - mse: 5.4601 - val_loss: 5.1924 - val_mae: 1.8558 - val_mse: 5.1924\n",
      "Epoch 387/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4451 - mae: 1.6098 - mse: 5.4451 - val_loss: 5.0842 - val_mae: 1.8207 - val_mse: 5.0842\n",
      "Epoch 388/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4436 - mae: 1.6118 - mse: 5.4436 - val_loss: 4.9160 - val_mae: 1.7975 - val_mse: 4.9160\n",
      "Epoch 389/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4271 - mae: 1.6113 - mse: 5.4271 - val_loss: 5.0185 - val_mae: 1.8066 - val_mse: 5.0185\n",
      "Epoch 390/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4097 - mae: 1.6042 - mse: 5.4097 - val_loss: 4.9971 - val_mae: 1.8128 - val_mse: 4.9971\n",
      "Epoch 391/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4392 - mae: 1.6128 - mse: 5.4392 - val_loss: 5.0431 - val_mae: 1.8113 - val_mse: 5.0431\n",
      "Epoch 392/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4105 - mae: 1.6073 - mse: 5.4105 - val_loss: 5.0308 - val_mae: 1.8202 - val_mse: 5.0308\n",
      "Epoch 393/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4103 - mae: 1.5984 - mse: 5.4103 - val_loss: 4.9946 - val_mae: 1.8162 - val_mse: 4.9946\n",
      "Epoch 394/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.3997 - mae: 1.5980 - mse: 5.3997 - val_loss: 5.0775 - val_mae: 1.8209 - val_mse: 5.0775\n",
      "Epoch 395/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4000 - mae: 1.6026 - mse: 5.4000 - val_loss: 4.9920 - val_mae: 1.8072 - val_mse: 4.9920\n",
      "Epoch 396/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4025 - mae: 1.6057 - mse: 5.4025 - val_loss: 5.0043 - val_mae: 1.8161 - val_mse: 5.0043\n",
      "Epoch 397/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4085 - mae: 1.5964 - mse: 5.4085 - val_loss: 5.2972 - val_mae: 1.8682 - val_mse: 5.2972\n"
     ]
    }
   ],
   "source": [
    "#Now, lets train the model\n",
    "model = nn_model()\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "history = model.fit(train_features, train_labels, epochs=1000, verbose=1, validation_split = 0.1,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Root Mean Square Error on validation set: 2.302\n"
     ]
    }
   ],
   "source": [
    "# show RMSE measure to compare to Kaggle leaderboard on https://www.kaggle.com/c/boston-housing/leaderboard\n",
    "rmse_final = np.sqrt(float(hist['val_mse'].tail(1)))\n",
    "print()\n",
    "print('Final Root Mean Square Error on validation set: {}'.format(round(rmse_final, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           loss        mae         mse    val_loss    val_mae     val_mse  \\\n",
      "0    585.537292  22.263453  585.537292  480.044098  20.923649  480.044098   \n",
      "1    557.710938  21.673540  557.710938  455.406952  20.322796  455.406952   \n",
      "2    530.473633  21.063927  530.473633  430.212738  19.697676  430.212738   \n",
      "3    502.001038  20.416204  502.001038  403.871521  19.014919  403.871521   \n",
      "4    472.778809  19.720312  472.778809  375.417694  18.261448  375.417694   \n",
      "..          ...        ...         ...         ...        ...         ...   \n",
      "392    5.410338   1.598368    5.410338    4.994578   1.816167    4.994578   \n",
      "393    5.399655   1.597989    5.399655    5.077547   1.820867    5.077547   \n",
      "394    5.400008   1.602639    5.400008    4.991995   1.807231    4.991995   \n",
      "395    5.402512   1.605711    5.402512    5.004295   1.816074    5.004295   \n",
      "396    5.408532   1.596388    5.408532    5.297152   1.868161    5.297152   \n",
      "\n",
      "     epoch  \n",
      "0        0  \n",
      "1        1  \n",
      "2        2  \n",
      "3        3  \n",
      "4        4  \n",
      "..     ...  \n",
      "392    392  \n",
      "393    393  \n",
      "394    394  \n",
      "395    395  \n",
      "396    396  \n",
      "\n",
      "[397 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 953us/step - loss: 15.6722 - mae: 2.7428 - mse: 15.6722\n",
      "Root Mean Square Error on test set: 3.959\n"
     ]
    }
   ],
   "source": [
    "mse, _, _ = model.evaluate(test_features, test_labels)\n",
    "rmse = np.sqrt(mse)\n",
    "print('Root Mean Square Error on test set: {}'.format(round(rmse, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, lets generate more test samples from test data and monitor them, as priduction data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (404,)\n",
      "(102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_features), np.shape(train_labels))\n",
    "print(np.shape(test_features), np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=np.shape(test_labels)[0]\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import the ml_monotor library\n",
    "import ml_monitor\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 13:59:44,503 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    }
   ],
   "source": [
    "my_monitor = ml_monitor.Monitor()\n",
    "my_monitor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 13:59:49,504 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 13:59:54,505 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 13:59:59,507 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:04,508 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:09,510 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:14,511 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:19,513 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:24,515 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:29,516 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:34,518 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:39,521 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:44,522 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:49,523 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:54,525 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:00:59,527 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:01:04,529 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:01:09,530 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n",
      "2021-05-25 14:01:14,532 [6242] INFO     ml_monitor.logging: Starting metrics logging thread...\n"
     ]
    }
   ],
   "source": [
    "epochs=100000\n",
    "for i in range(epochs):\n",
    "    indx=random.randint(0,num-1)\n",
    "    x_batch=np.expand_dims(test_features[indx,:],axis=0)\n",
    "    y_batch=np.expand_dims(test_labels[indx],axis=0)\n",
    "    mse, _, _ = model.evaluate(x_batch, y_batch, verbose=0)\n",
    "    my_monitor.monitor(\"n_rmse\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
